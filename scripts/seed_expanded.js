
import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';
import path from 'path';
import { fileURLToPath } from 'url';
import { seoulPlaces } from './data/seoul_places.js';

// Load environment variables from .env
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
dotenv.config({ path: path.join(__dirname, '../.env') });

const supabaseUrl = process.env.VITE_SUPABASE_URL;
const supabaseKey = process.env.VITE_SUPABASE_ANON_KEY;

if (!supabaseUrl || !supabaseKey) {
    console.error('Error: VITE_SUPABASE_URL and VITE_SUPABASE_ANON_KEY must be set in .env');
    process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);

async function seedExpanded() {
    console.log('ðŸŒ± Starting bulk data insertion...');
    console.log(`ðŸ“¦ Found ${seoulPlaces.length} records to insert.`);

    try {
        // 1. Clear existing data or just append? 
        // User asked to "bulk insert", implying append or fresh start.
        // Let's assume we want to KEEP existing 20 and ADD these.
        // But verify duplicates by name.

        // Process in batches of 50 to avoid payload limits
        const batchSize = 50;
        let insertedCount = 0;

        for (let i = 0; i < seoulPlaces.length; i += batchSize) {
            const batch = seoulPlaces.slice(i, i + batchSize);

            // We use simple insert since Upsert needs a unique key which we don't strictly have on 'name' in schema
            // but 'seed_db.js' had duplicates issue.
            // Ideally we check if exists first, but for now we just insert. 
            // User said "Bulk Insert", let's trust the data doesn't conflict with initial 20 too much 
            // (Initial 20 were sample mock data, these are real).
            // Actually, many of the initial 20 might overlap (e.g. Gangnam-gu Office).
            // To be safe, we can try to delete duplicates by name before inserting?
            // Or just run it. The task says "verify coordinates", so valid data is good.

            const { data, error } = await supabase
                .from('public_services')
                .insert(batch)
                .select();

            if (error) {
                console.warn(`âš ï¸ Batch ${i / batchSize + 1} Error:`, error.message);
            } else {
                insertedCount += data.length;
                console.log(`âœ… Batch ${i / batchSize + 1}: Inserted ${data.length} records.`);
            }
        }

        console.log(`ðŸš€ Bulk insert completed. Total inserted: ${insertedCount}`);

        // Verify count
        const { count, error: countError } = await supabase
            .from('public_services')
            .select('*', { count: 'exact', head: true });

        if (countError) throw countError;

        console.log(`ðŸ“Š Final Total records in 'public_services': ${count}`);

    } catch (err) {
        console.error('âŒ Error seeding database:', err.message);
        process.exit(1);
    }
}

seedExpanded();
